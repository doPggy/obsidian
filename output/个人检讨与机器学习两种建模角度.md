首先在这里感谢王然老师的教学，让我能够知道入门机器学习的路子，并能为之付诸努力。

其实这两周说是最困难的两周，关于机器学习的数学部分，我还知之甚少。还有太多的知识没有消化，在此我个人需要反思一下。

# 检讨
学习和接受知识的过程中，逐渐地不动手了。这个体现了两个问题：

不做笔记和不懂得抓重点。

什么这么说，首先学习的过程中失去笔记，印象浅不说，回头想复习时，依旧需要重啃书本，但是这样复习很容易变得浮躁没有效率，会觉得似曾相识从而漏掉不少东西。还有就是听课的过程中，遇到不懂的东西或者新知识，总是忘记去记录，然后就失去了了解更多知识的机会。

于是， 要不要记笔记就经常会困扰我。看一些记一些会打断，看完再记又等于再看一遍才记录。那么就不知道怎么记，就导致不懂的抓重点。

所以目前思考的结果是，学习过程中如果遇到新东西，就应该动手记录，以供后头查阅学习。记录笔记不用过于多，但要点一些关键。例如如果是直播，可以写一个题干，然后记录时间点，之后回看再精看。

同时还有个问题，身体上稍微的不适就容易让我的定力下降，是不是观看手机，虽然时间不长，马上清醒丢掉，但是除非是在数学推导，否则就容易不断重复这个打断学习进程的动作。要是这个时候卡在某个概念的学习上，那就是浪费时间了。

我已经在尝试更多的休息和更远的手机距离。利用 pad 专注看书这件事我已经实践过，有不错的效果，因为依靠此我看了统计学完全教程多个章节。

# 建模角度
检讨了半天，但还是喜人的一点是：我愿意花更多的时间在学习上，数学上的学习，起码是老师提供的资料和讲义我愿意自己阅读和推导一遍。当然，对于英文资料的阅读速度还是不足。

那就拿这两周很小的一部分的知识做些记录吧。

机器学习可以有两种建模角度，或者还有更多。掌握更多的角度是为了更好地解决问题。

1. 函数视角
2. 概率视角

函数视角是我初学时，接触的最多的视角。

假设有一堆数据，$(x, y)$ 用 $x$ 预测 $y$。我们假设一个 $f$ 属于一个函数集合 $F$，这个函数集合里头可能包含真实的 $f_0$

利用损失函数 $c$ 的值不断变小来逼近这个真实的 $f_0$
$$\sum c(y_i, f(x))$$

这时候我们就有一个估计 $f^*$，我们肯定希望最好是两者相等。但这个不可能：

因为为了 $F$ 能够包含真实 $f_0$，我们就需要 $f$ 足够复杂才有可能包含到。而不断逼近的过程中我们又希望 $f$ 简单一些，这是矛盾的。

1. $F$ 不包含真实的 $f_0$
2. $f$ 不好求解
3. $(x, y)$ 不可能有无限多个


那么概率视角，可以说需要引入随机变量。需要随机的原因有很多，信息缺乏，测量、估计、评估、优化误差的存在。

例如如果硬要用身高预测体重，这个就是模型假设上就有问题，估计误差就出来了，同时信息上缺乏两者的关联。如果硬用函数逼近，那么会对训练集过拟合，在验证集上 bias 特大。

同时注意一下 bias, variance 的大小与过拟合欠拟合的关系。这个是不绝对的，主要要看针对是训练集还是验证集。目前网上流传最广的靶图，也是不一定的，这图有些老外也在用这个。

同时上文提到的估计误差，测量误差，评估误差、优化误差，这个其实还是有一些东西的，我就挖坑，以后再说。

这里单独说一下评估。在模型训练好后，肯定要验证其正确性。如果误差很大，就需要用概率的角度多

$$y = f(x) + e$$

$e$ 为误差，可以假设它服从一个分布，例如服从正态分布，反之就可以直接用函数逼近的角度：

$$y = f(x)$$

# 总结
主要是检讨和很简短地 "抄写" 了机器学习两种建模角度。毕竟是临时看课件然后搬过来的，加了一点自己的理解，但也都是老师的。

所以还需要再接再厉。