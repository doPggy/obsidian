训练集为什么不能搞超参数。因为训练集要充分拟合，而不考虑泛化能力。而在验证集上，不管你的数据给多少，也只是看效果如何。 

过拟合的理解：身高去预测体重。为了拟合，身高可能潜在承担了太多其他指标，所以验证的时候能力不太行。

kfold 为什么要和测试集保持一致。kfold 的验证和测试集要是不太一致，说明泛化能力或者是哪个环节出问题了。

kfold 中每个参数不一定一样。

分箱是个啥？分箱是一种数据预处理方法。可以将多个连续值分组，可以达到连续变量离散化的目的。那么连续变量离散化还有什么好处：引入非线性，提高模型表达力，对异常数据有很强的鲁棒性。

分箱方法就列举一下，以后碰到再说：
1. 有监督分箱：卡方分箱，最小熵分箱。

GBDT 是一般的拟合模型，最终结果是得分。而随机森林或者决策树结果是分类。

本章的东西更多是需要实践，所以会存在不理解的地方。

# xgboost
xgboost 原理官网就有，但是看了一半！

# lightgbm
GOSS: gradient-based One-Side Sampling


# catboost
针对分类问题转化成 target mean。


# 代码实现准则-调参

## 树的复杂度
多和叶子个数相关，也有深度影响。leave wise growth 和 depth wise growth。

而且叶子个数与学习率高度相关

50 棵树过拟合和 1000 棵树过拟合哪个好？首先，学习率高，模型变化很大，学习率小，可能模型表现基本都差不多，或者收敛的慢。那么如果用很小学习率 1000 棵树，可能要跑很久，这个时候就要考虑算力问题。

树越复杂，叶子多的更容易过拟合。与之对应的学习率可能也要随之变化。

## 数据筛选随机性
随机选变量或观测。

## DART
类似 dropout 一种防止过拟合的方法，每次 boosting 的时候将前一轮树随机扔了。

容易减慢模型拟合结果。


## 还有很多参数如何寻找最优
在参数寻找的时候，有些模型是要考虑超参数还有变量选择。这个就涉及是否公平的问题了。举个例子，一开始使用 20 变量，a 超参数训练。后头又加了 20 个，却选择一样的超参数，并且不怎么调参，那么就不能说明这 20 个新加的有效，甚至效果还不如之前（比如过拟合）。

所以变量不一样了，参数或超参数也要变化，同时调参粒度是要一致的， 不然不能评估变量变化后的效果，这就是不公平。

参数寻找可以分成三个阶段（这些都是实践上的总结，一定需要实践）：
1. 随机探索。
2. 顺序搜索
3. 贝叶斯优化

### 随机探索
用一些极端方法，例如变量多多的。

记录各种 metric，收集模型运行信息。有时候会发现模型对某类指标好，另一个模型则对另外的指标效果好，这种信息就可以记录，并且可以考虑集成。

还可以检查变量重要性，比如树模型中，造了 20 个树，变量被选择次数哪些是最多的。

这样可能就能确定参数的合理范围然后就可以开始顺序搜索。

### 顺序搜索
可以按照参数的重要性开始一个个搜索了。（搜索，不断地调参)

例如先学习率+深度（树模型）。

这样尽量找一个合理范畴。尽量减少这个阶段给后头阶段带来的影响。

### Hyperopt
基于贝叶斯方法的优化。

已经调过的参数，范围缩小，没有调过的范围扩大。这个挺好理解的。已经调过的，应该是只有更小的偏差了。同时多次初始化效果比一次初始化跑多次来得好。(由于没用过，只能是概念上理解。后头希望能用上)

## 调参效果
要在 kfold 选取并验证。

有使用模型集成，最好构建 pipeline。


## 实践经验考
模型训练过程中展示训练和验证的误差，可以关心一下他们相比上一轮有明显下降时做了什么。

假如用 5-flod，要用多少课树，该如何选择？在一个 fold 上 300 达到最优，另一个 500 达到最优，那么取平均，就是 400 个。这个合理吗？那选最多的呢？选效果最好的时候的树的数量？

early stop：在验证集上误差没有减小就停止的验证次数。如果大，可能会又偏离最好的轮数或者是训练到结束，可能浪费算力还过拟合。如果小，可能就没逼近好结果就停止了。


# 线性模型
线性模型 $x^t\beta$ 形式，$x$ 为 样本输入，$\beta$ 为估计参数

 线性模型比树模型复杂，所以相对的，用较少的变量，有合适样本情况下，能得到更好的效果。但是线性模型不是贪婪的，（不是树那样一个一个分割点找），是一次性去拟合，高位数据就容易让线性模型过拟合。
 
 线性模型对异常值很敏感，画个图就知道了。
 
 ## 线性回归逻辑回归
线性回归针对目标连续且取全部实数值得情况 

一些情况下，不用取值或者要改变模型（取 log），因为是异常值。

逻辑回归同理。

GLM 参考讲义。

## SVM
吴恩达讲义

minimax.pdf 记得背诵，主要是为了对偶的证明

核函数，因为推导之后有个内积，这个不好计算，想利用核函数。尤其是非线性核函数增加了非线性性,使得更复杂，表现力更强。

RKHS 空间

缺点是 svm 很慢，svm 不能输出概率值，集成可能有问题。


## knn
处理分类问题，这个可以查找其他资料，以前也做过。

最大问题：计算很慢，推测很慢。而且是每次推测都要遍历所有观测。

但是 knn 有技巧很好用。


## 降维方法
这两个都没听过，需要查询。sklearn 有 api。

主成分方法？为了找到线性独立的，可以解释的 X 变量的降维变量。同时这个方法一定存在损失，因为原本比如 5 个 x 解释 5 个 y，现在 3 个 x 解释 5 个 y。我们还需要最小化这个损失。

（感觉有时候讲的东西比较模糊）降维情况是否需要标准化？需要，如果降维后，有一个变量特别大，那么其他变量都不需要解释。

t-SNE ？

## knn 与 t-SNE 结合
做完 t-SNE 后，找他的 knn，比如最近五个点，再放到模型去。这样往往能找到一些全局的参数或变量。（还是不能完全理解，应该需要实践才能懂）


# 模型评价指标
sklearn 评价指标，看他的网站链接

混淆矩阵？

比较模型用 f1 还是 accuracy。其实越简单的评价指标会好一些，复杂的话可能不知道哪里出问题，万一是指标本身有问题。

但是复杂的指标可以发现一些问题，比如哪一类预测的好。

## ROC
ROC?还是不懂说的方法论

基本思路：随着阈值不同，正负样本区分不同。（违约率多少算个阈值，决定给不给。

如果这个阈值得不到，也是预测的，根据这个预测来做 ROC，很有可能即使 ROC 高，预测结果还是差。