需要注意的是，这个是偏向实战的内容。实战后再回头看看，应该会有更多收获。

集成 1000 棵树和集成 1000 个 lr，哪个效果好？树更好。为什么？

# 集成学习简介
多个模型的结果合并到一起进行预测。(什么模型可以合并，怎么做合并？)

一个问题:
```
5-fold 出了 5 个模型，怎么做对测试集的预测？五个模型集成，比如算术平均。

那如果不集成，只用其中一个好的模型做预测，和集成比较，效果如何？每个模型都是不如集成的，差距挺大的。
```

可见最简单的集成方式，往往也能带来更好的效果(但是需要实践)

但是只在预测性建模中使用。因为如果是比如分析两者之间是否有关系这样的模型，你无法判断哪种是对的，那就无法评估集成带来的是否是更好的结果，而预测性比较好判断。

## 为什么会有效
首先，这个没有绝对的理论支撑，只有实践经验。

然后可以直观地分析，不同模型关注的方卖弄是不同的，可以做到互补。

原因可以有以下三种：
1. Error Correction Encoding
2. 各取所长
3. 过拟合(?)


### Error Correction Encoding

这个是纠错码，但是只是用来解释的一个例子。我们以这种（3,1）重复码为例。

发送一串 1110110011，通过这种重复码发送。

```
1010110011
1110110011
1110110011
```

对于每一位来说，若非 3 个相同，以重复次数多的数为准，在集成中可以理解为投票。以第二位来说，从上到下是 0 1 1，那么这一位就被认为是 1.

假设每一位污染概率 0.1，同时每一位污染相互独立。那么最终正确传输的概率是多少？是 0.972.

我们把这个例子来理解模型集成。这种纠错码就是一种集成，来保护信息传输的正确性，那么模型的集成一样也是这么做的，大概率可以保护模型预测的正确性。（当然具体怎么做，我还没试过）


### 各取所长
模型上限其实还是数据，特征。

数据如果可以分成三种：
1. 很容易预测
2. 有一定难度
3. 很难预测

很容易预测的话，各种模型都可以很好的出效果。很难预测的话，各个模型可能都不咋地。只有预测有一定难度的数据，才存在提升的可能。

如果我们**加适当的权重和加权平均**得到结果，可以说是综合各个模型的优点，可能可以得到一个好的结果。

### 过拟合
在很多非结构化数据中存在。

这个角度是在说，集成是作了一种合理的过拟合。

这个比较反常识，在观念中，过拟合是不好的。但是在预测性建模的例子中，过拟合的往往是最好的。

但是过拟合就是过拟合，可能不稳定，换个数据集就崩了。但又由于集成的原因，不同类型的模型可能抵御各种不稳定的异常，反而健壮起来。

数据信息量较小的情况下尤其有意义，因为一般来说拿到的数据有效信息是不多的，如果没有合理的过拟合，只考虑一般的逼近收敛，一般准确率是没法上的特别高的。


## 集成学习启示
1. 被集成的模型需要有一定准确性。用数据分成三种的角度，如果很容易预测的数据上，模型都预测很垃圾，那就不要指望集成能有多好。
2. 在预测上有一定区分。区分是什么？个人理解就是对于同样的一份数据可能存在不同部分的不一样的预测，假设我们 5 个模型对于 2 - 225 观测数据的预测都是一样的，那么对于这段数据来说，大家预测都一样，怎么加权重都没有用。

ok 这样能解释开头的问题。为什么树模型集成效果更好？因为树模型或者那随机森林来说，各个树对同一数据存在很大的区分，所以集成发挥的作用更大更好。

那么我们是否要用，什么时候用，该怎么用，也是可以考量的东西。

## 是否要用
如果打比赛。要。

如果是项目中，需要考量其中的模型是否需要很多的时间导致拖效率。

## 什么时候
特征工程 -> 调参 -> 集成

早点开始优点：早点看到实际的效果，充分利用提交次数等。

早点开始缺点：消耗算力。消费精力(因为没法针对一个模型了，判断不出谁比较差), 思维定式(集成多了，可能不敢去替换模型。)

## 该怎么用
首先要知道，我们要用哪些模型拿来集成。

是需要不同的模型，但是不同的来源有如下几个：
1. 不同数学形式、**初始化**、训练方式不同的**模型**。
2. 不同的数据(不同数据扩充结果变成新的观测，去掉不容易预测的观测)
3. 不同的变量。(这个可能需要不同的人来做，不然就容易构造相似的变量)

那该选择哪些子模型进行集成?

集成方式越复杂，对被集成模型的输入要求越小。因为方式越简单，那么调整就越有限，那么以下三个要求会要求更高。

1. 同样模型选预测准确度高的
2. 不同模型预测准确度应该一致，并且有一定区别。因为没有什么区别的话，集成没啥效果。
3. 预测粒度尽可能一致。关于预测粒度有个问题，树输出若是 01 分类(0 1 算是他的粒度)，lr 输出概率值(0.x 是粒度)，那么这两个集成存在什么问题？树影响会更大，因为 lr 都是 0 - 1 的概率值，但是又有概率值这样小数的粒度，就等于放大了。


那么有什么方法来集成

1. 加权求和
2. stacking

加权求和中，可以用：
1. 算术平均。正好有一个问题，那么用概率做平均还是分类做平均哪个更好。概率，粒度更细。同时要注意，保证粒度尽量一致，保持模型可信度类似。
2. 几何平均
3. 排序平均。三分类来说，将输出的某类的概率值进行排序，并编码 rank，然后每一类的 rank 进行平均。这样统一了粒度，同时扩大粒度，扩大了区别。

那么加权中的权就是权重了。这个权重也存在怎么加的问题。

### 权重
权重的确定也比较有随机性。例如五个模型中，最好的模型 3 票，其他模型共 4 票，各 1 票。虽然最好模型有大权重，但是其他模型总共票数超过最好模型，说明这个最好模型也是不能通过的。

权重的确定能否算作一个优化任务去调参？不行，因为真实的情况你也不知道，无法衡量。就算你能搞收敛，在验证集得到结果，不具有代表性。而且 kfold 的表现要和测试集尽量一致，而测试集表现也未知。

同时这个权重是否好求解？换个思路，是处处局部最优，还是很少局部最优。应该是很多局部最优，因为权重的变化小的话影响其实是不大的，那变化大的话，很有可能就是要替换一个模型，而不是集成了。

但是用权重往往是最后考虑的。