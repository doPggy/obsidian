模型评估出问题的话后头的算法对于整体的准确性的帮助就无法评估

所以什么是模型评估？

# 传统评估方法
训练、验证、测试集

训练集：对模型参数估计
验证集：对超参数选择(例如对 L1 损失的 λ 的选择)
测试集：测试模型最终表现，可用来预测的

为什么还需要测试集？要验证泛化能力。如果在验证集上验证，超参数一定是对于验证集最优。

测试集替代验证集也是危险的。用测试集去测试，选择超参数，去测出模型参数。用一些非正常手段去猜，就能对测试集来说，完全预测正确。但这个的泛化能力可想而知。

当然，如上评估方式有什么问题。

有一个问题是，数据量是不够的。

同时训练集不够，精度不够。验证集不够，准确性不够。这两者的取舍是个问题。

但是吴恩达也有一个观点，可以大量数据组训练集，剩下一些做验证。但是这是需要验证集有很好的估计效果。

那么数据量不够的时候怎么办？

# k - fold
kfold 将训练集平均分 k 份，其中一份为验证，其余为训练，循环 k 次。为了充分利用不多的数据集合。

测试集需要提前选好。

k-fold 准确率一般要取平均。

k - fold 一般随机选取。而 k - fold 和测试集依旧会有差别。而我们希望两者尽量一致

可能原因：
1. kfold 本身随机性
2. 训练与测试集本身差异。训练用北京的消费数据，但是测试集都是山东的消费数据。这种情况尤其在工作中，这种情况如果存在一定要提前说。

POC：概念验证。这么想：对一个问题用不同模型都跑一遍，结果看谁比较好。

在 kfold 和 test 比较一致的时候，还希望各 fold 之间用同样模型跑出来，效果应该差不多，可以是预测准确率等等。这里应该说的是各个被选中作为验证的 fold 被验证的时候效果应该差不多

kfold 怎么选？
1. k 少的话，训练就少。k = 3 和 k = 5 看看谁训练数据多就知道了。精度不够
2. k 多的，验证就少，准确不够。而且如果数据不少的时候，做 k fold 可能导致算多个模型，导致算力不足


# 分布匹配问题
训练验证测试集的分布，希望是一个的。但比如 19 年预测 20 年的经济，那疫情这种预测外的事情就导致严重错估。

较为好的应对方法：
1. 样本足够代表性。北京代表全国 -> 每个省抽样代表全国
2. 模型多样性：集成

那么集成思路？

# 集成思路
综合多个模型的共同结果，因为模型都有自己长短处。（怎么做这个，还没实践过，所以挖坑。）

模型集成举例：一个数据集 kfold 将其预测概率取平均。在比赛里这是单模型，但其实算多模型（理解为不同参数造不同模型，所以是一种集成）

用 kfold 选超参数(例如 λ)，再使用同样的参数训练，这样的问题是什么：超参数选择与观测数量关系很大。先用数据集 kfold 和用整个数据集，最佳参数是不一样的。

 所以需要更复杂的建模方式。
 
 # 更复杂建模
 常见策略是：以一个模型为基础，每次增加，但数学形式要有所不同。如果都差不多，那么结果都差不多，达不到集成的思路。
 
  对于模型集成存在都预测得好或者不好的情况，这个如何集成都没有办法提升效果了。所以要集中在部分模型预测好，又部分预测不好的情况下去提升。
  
 # adaboosting 残差学习
 adaboosting:
 
``` 
 训练两个模型，第一个预测得到后，预测不好的部分在下一个模型增加权重。就是在下一个模型弥补上一个模型不好的点。
``` 

GBDT 已经取代这方法。（具体如何使用，还是挖坑


# 多模型单模型技术方案选择
1. 一个模型。
2. 同样模型 kfold
3. 多个模型复杂集成

主要考虑算力（knn 特别耗），算力足够尽量不用单模型，多模型其实更稳定，单模型（逻辑、线性回归）表现形式简单并不是就代表稳定。

可解释性不一定是限制模型应用，理论上，好的模型解释性和预测精度应该要相辅相成。但很多解释性好的模型，和一些结果会有矛盾。因为这样的模型数学形式可能较为简单，可能估计偏差大(回想之前机器学习建模思路中，函数角度，更复杂函数才可能逼近真实模型)，虽然可解释，但是是错的。(比如说线上问题，只是说线上有服务端问题，虽然解释了有问题，但是还是无法定位到真正的问题。)

不过解释性不能丢了，如果出现几个反常例子（高收入一般高消费，但是总有几个样本是高收入低消费），为了解释这几个反常例子，可能又要引入一些变量。而这个就不能放弃解释性而丢弃这种例子。

那么变量好，模型就可以用简单形式吗。

核心问题，数据和业务之间关系复杂。经验只是针对很小的样本，很少变量和很粗略的关系，非常特殊的场景。

交叉效应是什么？（要查填坑）

# 鲁棒性
泛化能力，在不同数据集上表现尽可能一致。

本质上，无法根本解决。（为啥，个人还是从函数角度理解，为了更好的泛化，势必要更复杂，但是求解就更加困难，相互矛盾）

提升鲁棒性方法：
1. 多形式模型平均
2. 数据预处理（对取值限制，比如年龄有 200 岁的也能放进去处理。可以直接告警数据预处理问题。再比如职业分类，小众职业样本过小，不同的样本表现就可能造成模型大的不同表现）

数据预处理问题：
1. 数据超过范围的错值，尽量交给 ETL。
2. 探索性分析，需要了解数据。


# 树模型

## 决策树优点
1. 捕捉非线性和交叉效应（交叉效应？决策树中，多个变量才能得出一个结果，有羽毛能飞推断是鸟）
交叉效应重要的点：考虑高收入低收入群体消费习惯，事实上，男女是有差别的，但由于模型上如果不能同时考虑性别和收入，那么预测还是有问题的。如果同时考虑性别和收入，高收入男消费，高收入女消费特点就更容易体现。

2. 可解释性，因为能强规则写出一个树模型，自然解释性强。但是这个不好复现，因为树的分割在不同数据集上可能差距很大，所以这个可解释性是很危险的。

3. 贪婪算法导致收敛保证和计算快捷。贪婪是把所有分割点都遍历过去。因为无非是 if-else 的判断，一定是能有个结果的，并且比神经网络快多了。


## 决策树缺点
1. 准确率差，不好提高。因为模型表现力不好
2. 结构随机。
3. 调参对树用处不大

所以一般仅仅用于连续变量离散化，对于年龄和违约的模型，想对其分类，就把分类规则提取就拟合一个决策树用于分类。但是可能不如其他模型

# 随机森林
随机抽取部分变量或样本观测，分别拟合决策树（如果不这么做，那么多棵树可能都差不多），用多课树来预测。预测结果用投票决定。

一般只支持离散或连续的预测值。（离散的，连续的）

分箱 ：1 - 1000 为一个类，1001 - 2000 为一个类

extraTree : 随机抽取分割点，从中选取合适的。

## 优点
表现力强于单树，容易并行（因为随机抽取部分变量

## 缺点
这样树之间没有关联那么 adaboosting 就不好应用了。自定义损失函数就比较困难，因为还是基于树


# GBDT
梯度提升树，是对决策树的一系列针对一般建模情况的算法。

核心思想：根据上一轮运算结果进行对模型补充（涉及梯度就很想梯度下降的感觉，当然这只是方便记忆，不可混淆。）

原理：查看资料，虽然很少再用了，但是提供了很好的思路。

line search ？是什么？

在 GBDT 基础之上，四个著名的提升：XGBoost、LightGBM，CatBoost，NODE

XGBoost 的原理可以细看。同时去操作一下。