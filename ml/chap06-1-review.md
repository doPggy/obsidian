模型评估出问题的话后头的算法对于整体的准确性的帮助就无法评估

所以什么是模型评估？

# 传统评估方法
训练、验证、测试集

训练集：对模型参数估计
验证集：对超参数选择(例如对 L1 损失的 Lana 的选择)
测试集：测试模型最终表现，可用来预测的

为什么还需要测试集？要验证泛化能力。如果在验证集上验证，超参数一定是对于验证集最优。

测试集替代验证集也是危险的。用测试集去测试，选择超参数，去测出模型参数。用一些非正常手段去猜，就能对测试集来说，完全预测正确。但这个的泛化能力可想而知。

当然，如上评估方式有什么问题。